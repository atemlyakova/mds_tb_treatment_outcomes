{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1f7dfec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f7dfec6",
        "outputId": "ba503539-205e-4c55-f19a-ecc451022dc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch_tabnet\n",
            "  Using cached pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting numpy>=1.17 (from pytorch_tabnet)\n",
            "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting scikit_learn>0.21 (from pytorch_tabnet)\n",
            "  Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting scipy>1.4 (from pytorch_tabnet)\n",
            "  Using cached scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting torch>=1.3 (from pytorch_tabnet)\n",
            "  Using cached torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting tqdm>=4.36 (from pytorch_tabnet)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit_learn>0.21->pytorch_tabnet)\n",
            "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit_learn>0.21->pytorch_tabnet)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting setuptools (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading setuptools-80.8.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading fsspec-2025.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch>=1.3->pytorch_tabnet)\n",
            "  Using cached triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.3->pytorch_tabnet)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.3->pytorch_tabnet)\n",
            "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Using cached pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
            "Using cached scikit_learn-1.6.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
            "Using cached scipy-1.15.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.3 MB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached torch-2.7.0-cp312-cp312-manylinux_2_28_x86_64.whl (865.0 MB)\n",
            "Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "Downloading setuptools-80.8.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m478.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.0-py3-none-any.whl (196 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, typing-extensions, tqdm, threadpoolctl, sympy, setuptools, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, fsspec, filelock, triton, scipy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, scikit_learn, nvidia-cusolver-cu12, torch, pytorch_tabnet\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32/32\u001b[0m [pytorch_tabnet]m [torch]-cusolver-cu12]2]2]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.0 jinja2-3.1.6 joblib-1.5.0 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pytorch_tabnet-4.1.0 scikit_learn-1.6.1 scipy-1.15.3 setuptools-80.8.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.7.0 tqdm-4.67.1 triton-3.3.0 typing-extensions-4.13.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting optuna\n",
            "  Using cached optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from optuna) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from optuna) (25.0)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Using cached sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from optuna) (4.67.1)\n",
            "Collecting PyYAML (from optuna)\n",
            "  Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Using cached mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Using cached greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Using cached optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "Downloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "Using cached sqlalchemy-2.0.41-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "Using cached greenlet-3.2.2-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
            "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Using cached mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
            "Installing collected packages: PyYAML, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [optuna]2m6/7\u001b[0m [optuna]]my]\n",
            "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 PyYAML-6.0.2 alembic-1.16.1 colorlog-6.9.0 greenlet-3.2.2 optuna-4.3.0 sqlalchemy-2.0.41\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting optuna-integration[sklearn]\n",
            "  Using cached optuna_integration-4.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: optuna in ./.venv/lib/python3.12/site-packages (from optuna-integration[sklearn]) (4.3.0)\n",
            "Collecting pandas (from optuna-integration[sklearn])\n",
            "  Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from optuna-integration[sklearn]) (1.6.1)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from optuna-integration[sklearn]) (1.15.3)\n",
            "Requirement already satisfied: alembic>=1.5.0 in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (1.16.1)\n",
            "Requirement already satisfied: colorlog in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (6.9.0)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (2.0.41)\n",
            "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in ./.venv/lib/python3.12/site-packages (from optuna->optuna-integration[sklearn]) (6.0.2)\n",
            "Requirement already satisfied: Mako in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna->optuna-integration[sklearn]) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in ./.venv/lib/python3.12/site-packages (from alembic>=1.5.0->optuna->optuna-integration[sklearn]) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.2->optuna->optuna-integration[sklearn]) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in ./.venv/lib/python3.12/site-packages (from Mako->alembic>=1.5.0->optuna->optuna-integration[sklearn]) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas->optuna-integration[sklearn]) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas->optuna-integration[sklearn])\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->optuna-integration[sklearn])\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->optuna-integration[sklearn]) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->optuna-integration[sklearn]) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->optuna-integration[sklearn]) (3.6.0)\n",
            "Using cached optuna_integration-4.3.0-py3-none-any.whl (98 kB)\n",
            "Using cached pandas-2.2.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Installing collected packages: pytz, tzdata, pandas, optuna-integration\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [optuna-integration]ptuna-integration]\n",
            "\u001b[1A\u001b[2KSuccessfully installed optuna-integration-4.3.0 pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pytorch_tabnet\n",
        "%pip install optuna\n",
        "%pip install optuna-integration[sklearn]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9f60a65d",
      "metadata": {
        "id": "9f60a65d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report\n",
        "\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch.optim as optim\n",
        "from optuna import create_study, samplers, pruners\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe639a8",
      "metadata": {
        "id": "1fe639a8"
      },
      "source": [
        "# TabNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "WV8-fyPgSiWL",
      "metadata": {
        "id": "WV8-fyPgSiWL"
      },
      "outputs": [],
      "source": [
        "# Load preprocessed and SMOTENC-applied data\n",
        "X_train = pd.read_pickle('X_train_preprocessed_binary.pkl')\n",
        "y_train = pd.read_pickle('y_train_binary.pkl')\n",
        "X_test = pd.read_pickle('X_test_preprocessed_binary.pkl')\n",
        "y_test = pd.read_pickle('y_test_binary.pkl')\n",
        "\n",
        "# Convert data to numpy arrays (float32)\n",
        "X_train_np = X_train.values.astype(np.float32)\n",
        "X_test_np = X_test.values.astype(np.float32)\n",
        "y_train_np = y_train.values.astype(np.long)\n",
        "y_test_np = y_test.values.astype(np.long)\n",
        "\n",
        "# Split original X_train into train and validation sets (stratified)\n",
        "X_train_new_np, X_val_new_np, y_train_new_np, y_val_new_np = train_test_split(\n",
        "    X_train_np, y_train_np, test_size=0.2, stratify=y_train_np, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "wZNBB7R1SF0L",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wZNBB7R1SF0L",
        "outputId": "9ec572e4-42be-4f23-ed45-95c7c1417ff3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-05-22 17:25:59,381] A new study created in memory with name: no-name-185d5743-3c20-4d2a-b193-bae88c4be1da\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_logloss = 0.40333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:29:11,943] Trial 0 finished with value: 0.8679921521290556 and parameters: {'n_da': 29, 'n_steps': 5, 'gamma': 1.4488923914980236, 'lambda_sparse': 0.0010085722999723299, 'lr': 0.04023784742001718, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 47 and best_val_0_logloss = 0.48797\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:31:41,957] Trial 1 finished with value: 0.7903552016180002 and parameters: {'n_da': 20, 'n_steps': 4, 'gamma': 1.296739114141025, 'lambda_sparse': 1.6007887438907548e-05, 'lr': 0.0001955574747539243, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_logloss = 0.44795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:34:56,224] Trial 2 finished with value: 0.8313815137061785 and parameters: {'n_da': 28, 'n_steps': 5, 'gamma': 1.056714056485077, 'lambda_sparse': 0.0006990776028522564, 'lr': 0.0013449704691254453, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 48 and best_val_0_logloss = 0.46599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:39:35,609] Trial 3 finished with value: 0.8101044899150942 and parameters: {'n_da': 32, 'n_steps': 5, 'gamma': 1.4348136489275587, 'lambda_sparse': 0.0030755114934978957, 'lr': 0.0004006760757084667, 'batch_size': 64, 'virtual_batch_size': 32}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_logloss = 0.47887\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:42:29,874] Trial 4 finished with value: 0.8068850468504365 and parameters: {'n_da': 14, 'n_steps': 5, 'gamma': 1.4675932352339005, 'lambda_sparse': 0.0008795994665532686, 'lr': 0.0010117251381262199, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_logloss = 0.42405\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:44:22,462] Trial 5 finished with value: 0.8543237175549823 and parameters: {'n_da': 25, 'n_steps': 3, 'gamma': 1.2711902797214745, 'lambda_sparse': 0.0006990279868561147, 'lr': 0.0006957731434291811, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_logloss = 0.4311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:45:24,437] Trial 6 finished with value: 0.8469177344435721 and parameters: {'n_da': 26, 'n_steps': 4, 'gamma': 1.3716762506556128, 'lambda_sparse': 0.00033703124589087207, 'lr': 0.019821933506006115, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 0 with value: 0.8679921521290556.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:46:22,377] Trial 7 finished with value: 0.8762204881418457 and parameters: {'n_da': 11, 'n_steps': 3, 'gamma': 1.0973464197870746, 'lambda_sparse': 8.239533735344089e-05, 'lr': 0.023089778927531644, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 48 and best_val_0_logloss = 0.41315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:48:46,816] Trial 8 finished with value: 0.8623820282331074 and parameters: {'n_da': 24, 'n_steps': 4, 'gamma': 1.4676604992154696, 'lambda_sparse': 1.586932414401013e-05, 'lr': 0.0038173019764035764, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_logloss = 0.40088\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:49:43,680] Trial 9 finished with value: 0.8695483735429896 and parameters: {'n_da': 18, 'n_steps': 2, 'gamma': 1.0123785960108944, 'lambda_sparse': 0.0008592643394526734, 'lr': 0.005423054859880297, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_logloss = 0.39445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:51:21,609] Trial 10 finished with value: 0.8732387244717197 and parameters: {'n_da': 8, 'n_steps': 2, 'gamma': 1.1285269656894727, 'lambda_sparse': 8.232344565090338e-05, 'lr': 0.009163628516520226, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_logloss = 0.3995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:52:50,042] Trial 11 finished with value: 0.8735050678231951 and parameters: {'n_da': 8, 'n_steps': 2, 'gamma': 1.128928391452337, 'lambda_sparse': 7.388815269622689e-05, 'lr': 0.013464300707768904, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_logloss = 0.39455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:54:37,096] Trial 12 finished with value: 0.8741467131699309 and parameters: {'n_da': 8, 'n_steps': 3, 'gamma': 1.1558030624304767, 'lambda_sparse': 7.534968492374894e-05, 'lr': 0.01562448686100859, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_logloss = 0.39179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:56:01,270] Trial 13 finished with value: 0.8733037079765917 and parameters: {'n_da': 12, 'n_steps': 3, 'gamma': 1.1738032458608976, 'lambda_sparse': 7.027763052586538e-05, 'lr': 0.04929617166751565, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 40 with best_epoch = 30 and best_val_0_logloss = 0.39314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:58:24,177] Trial 14 finished with value: 0.8704287665062553 and parameters: {'n_da': 13, 'n_steps': 3, 'gamma': 1.208819447217574, 'lambda_sparse': 0.0001738037206065158, 'lr': 0.021162152099006046, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_logloss = 0.41039\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 17:59:59,087] Trial 15 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_logloss = 0.39153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:01:41,853] Trial 16 finished with value: 0.8756067946040547 and parameters: {'n_da': 17, 'n_steps': 3, 'gamma': 1.1965069892134053, 'lambda_sparse': 0.00019235047172349969, 'lr': 0.009860967308318118, 'batch_size': 64, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 49 with best_epoch = 39 and best_val_0_logloss = 0.40094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:03:49,759] Trial 17 finished with value: 0.8705047883051057 and parameters: {'n_da': 16, 'n_steps': 4, 'gamma': 1.3124466083508242, 'lambda_sparse': 0.006631419471548558, 'lr': 0.0056850188166267974, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_logloss = 0.39514\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:05:34,770] Trial 18 finished with value: 0.8730254361461398 and parameters: {'n_da': 21, 'n_steps': 2, 'gamma': 1.22350414350957, 'lambda_sparse': 0.00020520247871320653, 'lr': 0.0022414037542365824, 'batch_size': 64, 'virtual_batch_size': 32}. Best is trial 7 with value: 0.8762204881418457.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_logloss = 0.3896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:06:30,616] Trial 19 finished with value: 0.8788607768466442 and parameters: {'n_da': 16, 'n_steps': 3, 'gamma': 1.0740647203524574, 'lambda_sparse': 3.589061838642555e-05, 'lr': 0.030670564545334882, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_logloss = 0.39429\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:08:16,454] Trial 20 finished with value: 0.8761873732599109 and parameters: {'n_da': 15, 'n_steps': 4, 'gamma': 1.0009882476496454, 'lambda_sparse': 3.157133922159911e-05, 'lr': 0.030485451663916096, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 40 and best_val_0_logloss = 0.39621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:10:26,158] Trial 21 finished with value: 0.8719200044153175 and parameters: {'n_da': 15, 'n_steps': 4, 'gamma': 1.0157545692048624, 'lambda_sparse': 3.144170071016359e-05, 'lr': 0.030326562345826476, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39436\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:11:23,725] Trial 22 finished with value: 0.8730683430630555 and parameters: {'n_da': 11, 'n_steps': 3, 'gamma': 1.0786852540188767, 'lambda_sparse': 3.683913147415236e-05, 'lr': 0.02876802302562464, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_logloss = 0.3991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:12:40,502] Trial 23 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.39124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:13:49,644] Trial 24 finished with value: 0.8767718687297593 and parameters: {'n_da': 20, 'n_steps': 3, 'gamma': 1.1092403828386923, 'lambda_sparse': 4.3299230408260905e-05, 'lr': 0.0254408666638804, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_logloss = 0.39489\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:15:14,894] Trial 25 finished with value: 0.8746361368819667 and parameters: {'n_da': 22, 'n_steps': 3, 'gamma': 1.1043347854752141, 'lambda_sparse': 0.00011157329414158793, 'lr': 0.014718030869493828, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_logloss = 0.38843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:16:08,363] Trial 26 finished with value: 0.8779209195254958 and parameters: {'n_da': 23, 'n_steps': 2, 'gamma': 1.1492806409784664, 'lambda_sparse': 4.9841417394561676e-05, 'lr': 0.024529521127514862, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_logloss = 0.39579\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:17:00,707] Trial 27 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 47 and best_val_0_logloss = 0.47472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:18:59,774] Trial 28 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 30 with best_epoch = 20 and best_val_0_logloss = 0.393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:20:19,359] Trial 29 finished with value: 0.8748805816824853 and parameters: {'n_da': 19, 'n_steps': 2, 'gamma': 1.046914091451976, 'lambda_sparse': 0.00033102912121993523, 'lr': 0.03511538613937312, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_logloss = 0.38861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:21:59,705] Trial 30 finished with value: 0.8776244879210797 and parameters: {'n_da': 27, 'n_steps': 2, 'gamma': 1.11944159430174, 'lambda_sparse': 5.268998595671157e-05, 'lr': 0.007508822528272095, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_logloss = 0.38724\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:23:23,344] Trial 31 finished with value: 0.8782034642439392 and parameters: {'n_da': 27, 'n_steps': 2, 'gamma': 1.133247625789321, 'lambda_sparse': 4.818938607971681e-05, 'lr': 0.006739823865548595, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_logloss = 0.39755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:24:51,223] Trial 32 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_logloss = 0.40006\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:26:24,875] Trial 33 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 43 and best_val_0_logloss = 0.39357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:28:18,791] Trial 34 finished with value: 0.8734484520573065 and parameters: {'n_da': 27, 'n_steps': 2, 'gamma': 1.1269116506676928, 'lambda_sparse': 4.5065538286593647e-05, 'lr': 0.0015274331067290814, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_logloss = 0.39661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:29:26,111] Trial 35 finished with value: 0.8737701649156727 and parameters: {'n_da': 30, 'n_steps': 2, 'gamma': 1.1949296862566996, 'lambda_sparse': 2.118743572789168e-05, 'lr': 0.010308452469111797, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.40019\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:30:33,271] Trial 36 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_logloss = 0.39625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:31:28,243] Trial 37 finished with value: 0.8742207765617852 and parameters: {'n_da': 26, 'n_steps': 2, 'gamma': 1.0681003931775908, 'lambda_sparse': 0.0004768888401009075, 'lr': 0.012618736317691425, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 43 and best_val_0_logloss = 0.41231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:35:05,198] Trial 38 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_logloss = 0.39913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:36:19,746] Trial 39 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 48 and best_val_0_logloss = 0.41877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:38:11,190] Trial 40 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 23 with best_epoch = 13 and best_val_0_logloss = 0.39368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:39:18,797] Trial 41 finished with value: 0.8742768582166746 and parameters: {'n_da': 21, 'n_steps': 3, 'gamma': 1.1055255291541461, 'lambda_sparse': 5.712519250900497e-05, 'lr': 0.026369082010625253, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_logloss = 0.39772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:40:14,182] Trial 42 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.4023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:41:26,066] Trial 43 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.38992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:42:22,572] Trial 44 finished with value: 0.8767403561808216 and parameters: {'n_da': 25, 'n_steps': 2, 'gamma': 1.4247665325253143, 'lambda_sparse': 6.031976102888637e-05, 'lr': 0.01267948829012207, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 43 with best_epoch = 33 and best_val_0_logloss = 0.39161\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:44:08,926] Trial 45 finished with value: 0.87584767866458 and parameters: {'n_da': 19, 'n_steps': 3, 'gamma': 1.0849561298930759, 'lambda_sparse': 9.054686502318731e-05, 'lr': 0.02229072344732432, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 36 with best_epoch = 26 and best_val_0_logloss = 0.40829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:45:34,076] Trial 46 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 46 and best_val_0_logloss = 0.4468\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:47:04,548] Trial 47 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_logloss = 0.40432\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:48:19,684] Trial 48 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.39459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:49:08,767] Trial 49 finished with value: 0.8757486900927751 and parameters: {'n_da': 23, 'n_steps': 2, 'gamma': 1.1903416171277987, 'lambda_sparse': 9.319681983989883e-05, 'lr': 0.017574699827608467, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 44 with best_epoch = 34 and best_val_0_logloss = 0.3926\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:51:19,906] Trial 50 finished with value: 0.8750294206141921 and parameters: {'n_da': 17, 'n_steps': 4, 'gamma': 1.0910845810162202, 'lambda_sparse': 0.00026241908277544455, 'lr': 0.038385832081193144, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:52:12,308] Trial 51 finished with value: 0.8744130565214063 and parameters: {'n_da': 25, 'n_steps': 2, 'gamma': 1.421735136098819, 'lambda_sparse': 6.159918050004348e-05, 'lr': 0.011917232626710496, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 34 with best_epoch = 24 and best_val_0_logloss = 0.39063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:53:16,848] Trial 52 finished with value: 0.8747945898116547 and parameters: {'n_da': 26, 'n_steps': 2, 'gamma': 1.3933239204009644, 'lambda_sparse': 5.808676580179837e-05, 'lr': 0.013986988431572752, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_logloss = 0.39052\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:53:57,031] Trial 53 finished with value: 0.8778521972436312 and parameters: {'n_da': 24, 'n_steps': 2, 'gamma': 1.3400870293510372, 'lambda_sparse': 3.4564047775562033e-05, 'lr': 0.02320812667121171, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_logloss = 0.39341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:54:53,104] Trial 54 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_logloss = 0.39431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:56:02,316] Trial 55 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_logloss = 0.39452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:56:45,010] Trial 56 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_logloss = 0.38893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:58:06,604] Trial 57 finished with value: 0.8769527543214031 and parameters: {'n_da': 14, 'n_steps': 3, 'gamma': 1.4869902977623275, 'lambda_sparse': 4.087974227211583e-05, 'lr': 0.033327476097151004, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39691\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 18:59:17,955] Trial 58 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 44 and best_val_0_logloss = 0.40548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:01:14,625] Trial 59 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 35 with best_epoch = 25 and best_val_0_logloss = 0.39277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:02:25,732] Trial 60 finished with value: 0.8754369473063892 and parameters: {'n_da': 10, 'n_steps': 2, 'gamma': 1.488809448886558, 'lambda_sparse': 8.608133061682234e-05, 'lr': 0.008300928898541457, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 19 with value: 0.8788607768466442.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39484\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:03:45,420] Trial 61 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.41216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:05:14,592] Trial 62 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_logloss = 0.38735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:06:38,646] Trial 63 finished with value: 0.8799437759155108 and parameters: {'n_da': 20, 'n_steps': 3, 'gamma': 1.0325955847828647, 'lambda_sparse': 2.1351055688317123e-05, 'lr': 0.023858827454399014, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.39809\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:07:49,204] Trial 64 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 26 with best_epoch = 16 and best_val_0_logloss = 0.39463\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:08:54,129] Trial 65 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 32 with best_epoch = 22 and best_val_0_logloss = 0.39132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:09:59,301] Trial 66 finished with value: 0.8750415271301683 and parameters: {'n_da': 22, 'n_steps': 2, 'gamma': 1.2768278051927056, 'lambda_sparse': 7.652713307060714e-05, 'lr': 0.010401922127961993, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 38 with best_epoch = 28 and best_val_0_logloss = 0.40124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:12:29,717] Trial 67 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_logloss = 0.39208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:14:55,572] Trial 68 finished with value: 0.8744969119482411 and parameters: {'n_da': 26, 'n_steps': 4, 'gamma': 1.058529698290096, 'lambda_sparse': 1.6043149352752007e-05, 'lr': 0.024149529661534212, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 39 with best_epoch = 29 and best_val_0_logloss = 0.39525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:16:14,757] Trial 69 finished with value: 0.8749174353414128 and parameters: {'n_da': 19, 'n_steps': 2, 'gamma': 1.0226667177964601, 'lambda_sparse': 0.008778349771702849, 'lr': 0.004725544410009495, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:17:17,278] Trial 70 finished with value: 0.8769009455545053 and parameters: {'n_da': 28, 'n_steps': 2, 'gamma': 1.4005655345514842, 'lambda_sparse': 4.7514402253949774e-05, 'lr': 0.015347725819689548, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 28 with best_epoch = 18 and best_val_0_logloss = 0.40043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:18:17,882] Trial 71 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_logloss = 0.39315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:19:05,848] Trial 72 finished with value: 0.876033015181215 and parameters: {'n_da': 30, 'n_steps': 2, 'gamma': 1.4014632439133643, 'lambda_sparse': 3.750025919014925e-05, 'lr': 0.01855695678647789, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 20 with best_epoch = 10 and best_val_0_logloss = 0.39092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:19:47,233] Trial 73 finished with value: 0.8764172190264581 and parameters: {'n_da': 24, 'n_steps': 2, 'gamma': 1.4637929821842028, 'lambda_sparse': 6.921540809254471e-05, 'lr': 0.03451647787115135, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 41 and best_val_0_logloss = 0.39651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:23:03,721] Trial 74 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_logloss = 0.39595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:24:07,395] Trial 75 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_logloss = 0.39367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:25:02,555] Trial 76 finished with value: 0.875518844326228 and parameters: {'n_da': 28, 'n_steps': 2, 'gamma': 1.3447495315187168, 'lambda_sparse': 4.945352896337358e-05, 'lr': 0.027200741175484117, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_logloss = 0.39339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:25:46,860] Trial 77 finished with value: 0.8750860363800806 and parameters: {'n_da': 27, 'n_steps': 2, 'gamma': 1.0945406910192754, 'lambda_sparse': 3.456044546453727e-05, 'lr': 0.015666349655612442, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39014\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:27:28,907] Trial 78 finished with value: 0.8763508112255889 and parameters: {'n_da': 14, 'n_steps': 3, 'gamma': 1.215717505235619, 'lambda_sparse': 2.244590796598154e-05, 'lr': 0.021746400952767753, 'batch_size': 64, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 19 with best_epoch = 9 and best_val_0_logloss = 0.39233\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:28:10,727] Trial 79 finished with value: 0.8751590315499367 and parameters: {'n_da': 29, 'n_steps': 2, 'gamma': 1.4547229862221398, 'lambda_sparse': 6.811204361665223e-05, 'lr': 0.04021706179714751, 'batch_size': 128, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 42 with best_epoch = 32 and best_val_0_logloss = 0.39789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:30:12,843] Trial 80 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:31:20,549] Trial 81 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_logloss = 0.39225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:32:20,674] Trial 82 finished with value: 0.875043663574164 and parameters: {'n_da': 18, 'n_steps': 3, 'gamma': 1.1330373427909923, 'lambda_sparse': 4.5480726448649816e-05, 'lr': 0.024812213383747214, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.39073\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:33:28,985] Trial 83 finished with value: 0.8772961876937264 and parameters: {'n_da': 20, 'n_steps': 3, 'gamma': 1.0745822660399023, 'lambda_sparse': 2.9612369308517033e-05, 'lr': 0.027370229129354686, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 31 with best_epoch = 21 and best_val_0_logloss = 0.39485\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:34:42,272] Trial 84 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_logloss = 0.3939\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:35:28,990] Trial 85 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39731\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:36:44,047] Trial 86 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_logloss = 0.39617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:37:33,485] Trial 87 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 18 with best_epoch = 8 and best_val_0_logloss = 0.39098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:38:14,369] Trial 88 finished with value: 0.8762019722938822 and parameters: {'n_da': 20, 'n_steps': 3, 'gamma': 1.185195157156052, 'lambda_sparse': 2.466236416671219e-05, 'lr': 0.023661902772120873, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 24 with best_epoch = 14 and best_val_0_logloss = 0.39243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:39:31,980] Trial 89 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 25 with best_epoch = 15 and best_val_0_logloss = 0.39688\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:40:20,504] Trial 90 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 27 with best_epoch = 17 and best_val_0_logloss = 0.39642\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:41:23,793] Trial 91 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 21 with best_epoch = 11 and best_val_0_logloss = 0.38735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:42:12,211] Trial 92 finished with value: 0.8767521066227983 and parameters: {'n_da': 17, 'n_steps': 3, 'gamma': 1.0606522272018881, 'lambda_sparse': 2.9236294498952303e-05, 'lr': 0.02723896006146712, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 33 with best_epoch = 23 and best_val_0_logloss = 0.40276\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:43:24,733] Trial 93 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 37 with best_epoch = 27 and best_val_0_logloss = 0.39255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:44:45,004] Trial 94 finished with value: 0.8784358025284814 and parameters: {'n_da': 18, 'n_steps': 3, 'gamma': 1.251315735105469, 'lambda_sparse': 4.828463686900262e-05, 'lr': 0.020898828537235948, 'batch_size': 128, 'virtual_batch_size': 64}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.39315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:45:48,748] Trial 95 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 47 and best_val_0_logloss = 0.41672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:47:09,822] Trial 96 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 22 with best_epoch = 12 and best_val_0_logloss = 0.38772\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:48:28,398] Trial 97 finished with value: 0.8795866336942143 and parameters: {'n_da': 15, 'n_steps': 3, 'gamma': 1.2360371461857191, 'lambda_sparse': 0.00010781803759364498, 'lr': 0.021623285268213468, 'batch_size': 64, 'virtual_batch_size': 32}. Best is trial 63 with value: 0.8799437759155108.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Early stopping occurred at epoch 29 with best_epoch = 19 and best_val_0_logloss = 0.3978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:50:01,342] Trial 98 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stop training because you reached max_epochs = 50 with best_epoch = 49 and best_val_0_logloss = 0.40681\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n",
            "[I 2025-05-22 19:52:46,869] Trial 99 pruned. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best trial:\n",
            "  Value: 0.8799\n",
            "  Params:\n",
            "    n_da: 20\n",
            "    n_steps: 3\n",
            "    gamma: 1.0325955847828647\n",
            "    lambda_sparse: 2.1351055688317123e-05\n",
            "    lr: 0.023858827454399014\n",
            "    batch_size: 128\n",
            "    virtual_batch_size: 32\n"
          ]
        }
      ],
      "source": [
        "def objective(trial):\n",
        "    # Shared value for n_d and n_a\n",
        "    n_da = trial.suggest_int(\"n_da\", 8, 32)\n",
        "\n",
        "    params = {\n",
        "        \"n_d\": n_da,\n",
        "        \"n_a\": n_da,\n",
        "        \"n_steps\": trial.suggest_int(\"n_steps\", 2, 5),\n",
        "        \"gamma\": trial.suggest_float(\"gamma\", 1.0, 1.5),\n",
        "        \"lambda_sparse\": trial.suggest_float(\"lambda_sparse\", 1e-5, 1e-2, log=True),\n",
        "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 5e-2, log=True),\n",
        "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [64, 128]),\n",
        "        \"virtual_batch_size\": trial.suggest_categorical(\"virtual_batch_size\", [32, 64])\n",
        "    }\n",
        "\n",
        "    # Initialize TabNetClassifier\n",
        "    model = TabNetClassifier(\n",
        "        n_d=params[\"n_d\"],\n",
        "        n_a=params[\"n_a\"],\n",
        "        n_steps=params[\"n_steps\"],\n",
        "        gamma=params[\"gamma\"],\n",
        "        lambda_sparse=params[\"lambda_sparse\"],\n",
        "        optimizer_fn=optim.Adam,\n",
        "        optimizer_params=dict(lr=params[\"lr\"]),\n",
        "        verbose=0,\n",
        "        device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    )\n",
        "\n",
        "    # Train with early stopping\n",
        "    model.fit(\n",
        "        X_train=X_train_new_np,\n",
        "        y_train=y_train_new_np,\n",
        "        eval_set=[(X_val_new_np, y_val_new_np)],\n",
        "        eval_metric=['logloss'],\n",
        "        max_epochs=50,\n",
        "        batch_size=params[\"batch_size\"],\n",
        "        virtual_batch_size=params[\"virtual_batch_size\"],\n",
        "        drop_last=False,\n",
        "        patience=10\n",
        "    )\n",
        "\n",
        "    # Predict probabilities for ROC AUC\n",
        "    y_proba = model.predict_proba(X_val_new_np)\n",
        "\n",
        "    # Convert y_val to 1D and use class 1 probabilities\n",
        "    roc_auc = roc_auc_score(y_val_new_np.ravel(), y_proba[:, 1])\n",
        "\n",
        "    # Report metric for pruning\n",
        "    trial.report(roc_auc, step=50)  # Simulate per-epoch reporting if needed\n",
        "\n",
        "    if trial.should_prune():\n",
        "        raise optuna.TrialPruned()\n",
        "\n",
        "    return roc_auc\n",
        "\n",
        "# Run optuna study with pruning & TPE\n",
        "study = create_study(\n",
        "    direction=\"maximize\",\n",
        "    sampler=samplers.TPESampler(),  # Faster convergence\n",
        "    pruner=pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=5)\n",
        ")\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "# Print Best Hyperparameters\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(f\"  Value: {trial.value:.4f}\")\n",
        "print(\"  Params:\")\n",
        "for key, value in trial.params.items():\n",
        "    print(f\"    {key}: {value}\")\n",
        "\n",
        "best_params = trial.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "16d0bc0d",
      "metadata": {
        "id": "16d0bc0d",
        "outputId": "969dc7b8-e8bc-4fa5-82b7-3bab365b783d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retraining best model for loss visualization...\n",
            "\n",
            "Early stopping occurred at epoch 25 with best_epoch = 15 and best_valid_logloss = 0.39323\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# After Optuna study completes\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "# Retrain with best parameters\n",
        "print(\"Retraining best model for loss visualization...\")\n",
        "\n",
        "# Initialize model using best params from study\n",
        "plot_model = TabNetClassifier(\n",
        "    n_d=best_params['n_da'],              # Shared embedding size\n",
        "    n_a=best_params['n_da'],\n",
        "    n_steps=best_params['n_steps'],\n",
        "    gamma=best_params['gamma'],\n",
        "    lambda_sparse=best_params['lambda_sparse'],\n",
        "    optimizer_fn=torch.optim.Adam,        # Same optimizer\n",
        "    optimizer_params={\"lr\": best_params['lr']},\n",
        "    verbose=0,\n",
        "    device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Retrain on full train/val set for loss tracking\n",
        "plot_model.fit(\n",
        "    X_train=X_train_new_np,\n",
        "    y_train=y_train_new_np,\n",
        "    eval_set=[(X_train_new_np, y_train_new_np), (X_val_new_np, y_val_new_np)],\n",
        "    eval_name=[\"train\", \"valid\"],\n",
        "    eval_metric=[\"logloss\"],\n",
        "    max_epochs=50,\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    virtual_batch_size=best_params[\"virtual_batch_size\"],\n",
        "    drop_last=False,\n",
        "    patience=10\n",
        ")\n",
        "\n",
        "# Extract loss history\n",
        "train_losses = plot_model.history[\"train_logloss\"]\n",
        "valid_losses = plot_model.history[\"valid_logloss\"]\n",
        "\n",
        "# Plot training/validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(valid_losses, label='Validation Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Log Loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "H8wwV9A7Sr9n",
      "metadata": {
        "id": "H8wwV9A7Sr9n",
        "outputId": "cca74324-fffe-4045-aeee-872b9e67b1c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retraining final model on full dataset...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/at/Downloads/001/.venv/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test ROC AUC (OvR weighted): 0.8425\n",
            "Test Weighted F1 Score: 0.7980\n"
          ]
        }
      ],
      "source": [
        "# After Optuna study completes\n",
        "best_params = study.best_trial.params\n",
        "\n",
        "# Retrain final model on the full dataset\n",
        "print(\"Retraining final model on full dataset...\")\n",
        "\n",
        "# Initialize model with best parameters from Optuna\n",
        "best_model = TabNetClassifier(\n",
        "    n_d=best_params['n_da'],\n",
        "    n_a=best_params['n_da'],\n",
        "    n_steps=best_params['n_steps'],\n",
        "    gamma=best_params['gamma'],\n",
        "    lambda_sparse=best_params['lambda_sparse'],\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params={\"lr\": best_params['lr']},\n",
        "    verbose=0,\n",
        "    device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Train on full training dataset\n",
        "best_model.fit(\n",
        "    X_train=X_train_np,\n",
        "    y_train=y_train_np,\n",
        "    max_epochs=50,\n",
        "    patience=10,\n",
        "    batch_size=best_params[\"batch_size\"],\n",
        "    virtual_batch_size=best_params[\"virtual_batch_size\"],\n",
        "    drop_last=False\n",
        ")\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = best_model.predict(X_test_np)\n",
        "y_proba = best_model.predict_proba(X_test_np)\n",
        "\n",
        "# Evaluate metrics\n",
        "roc_auc = roc_auc_score(y_test_np, y_proba[:, 1], multi_class=\"ovr\", average=\"weighted\")\n",
        "f1 = f1_score(y_test_np, y_pred, average=\"weighted\")\n",
        "\n",
        "# Output results\n",
        "print(f\"Test ROC AUC (OvR weighted): {roc_auc:.4f}\")\n",
        "print(f\"Test Weighted F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2678f961",
      "metadata": {
        "id": "2678f961",
        "outputId": "ac85710d-9022-4aff-c772-8a8c9dd14148"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.858     0.859     0.858      3297\n",
            "           1      0.650     0.647     0.648      1330\n",
            "\n",
            "    accuracy                          0.798      4627\n",
            "   macro avg      0.754     0.753     0.753      4627\n",
            "weighted avg      0.798     0.798     0.798      4627\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print classification report\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test_np, y_pred, digits=3))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
